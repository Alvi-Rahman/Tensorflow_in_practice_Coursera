# Tensorflow In Practice Specialization

## Course 1: Introduction to TensorFlow for AI, ML and DL

This first course introduces you to Tensor Flow, a popular machine learning framework. You will learn how to build a basic neural network for computer vision and use convolutions to improve your neural network.

#### Week 1: A New Programming Paradigm

- [Week 1 - Predicting house price](https://github.com/Alvi-Rahman/Tensorflow_in_practice_Coursera/blob/master/1.%20Introduction%20to%20TensorFlow%20for%20Artificial%20Intelligence%2C%20Machine%20Learning%2C%20and%20Deep%20Learning/Exercise_1_House_Prices_Question.ipynb)

#### Week 2: Introduction to Computer Vision

- [Week 2 - Classifying Fashion MNIST with MLP](https://github.com/Alvi-Rahman/Tensorflow_in_practice_Coursera/blob/master/1.%20Introduction%20to%20TensorFlow%20for%20Artificial%20Intelligence%2C%20Machine%20Learning%2C%20and%20Deep%20Learning/Exercise_2_Question.ipynb)

#### Week 3: Enhancing Vision with Convolutional Neural Networks

- [Week 3 - Classifying Fashion MNIST with CNN](https://github.com/Alvi-Rahman/Tensorflow_in_practice_Coursera/blob/master/1.%20Introduction%20to%20TensorFlow%20for%20Artificial%20Intelligence%2C%20Machine%20Learning%2C%20and%20Deep%20Learning/Exercise_3_Question.ipynb)

#### Week 4: Using Real-World Images

- [Week 4 - Classifying emotion with CNN](https://github.com/Alvi-Rahman/Tensorflow_in_practice_Coursera/blob/master/1.%20Introduction%20to%20TensorFlow%20for%20Artificial%20Intelligence%2C%20Machine%20Learning%2C%20and%20Deep%20Learning/Exercise_4_Question.ipynb)

## Course 2: Convolutional Neural Networks in TensorFlow

This second course teaches you advanced techniques to improve the computer vision model you built in Course 1. You will explore how to work with real-world images in different shapes and sizes, visualize the journey of an image through convolutions to understand how a computer “sees” information, plot loss and accuracy, and explore strategies to prevent overfitting, including augmentation and dropouts. Finally, Course 2 will introduce you to transfer learning and how learned features can be extracted from models.

#### Week 1: Exploring a Larger Dataset

- [Week 1 - Classifying Cats and Dogs](https://github.com/Alvi-Rahman/Tensorflow_in_practice_Coursera/blob/master/2.%20Convolutional%20Neural%20Networks%20in%20TensorFlow/Exercise_1_Cats_vs_Dogs_Question-FINAL.ipynb)

#### Week 2: Augmentation, a Technique to Avoid Overfitting

- [Week 2 - Improving Cats and Dogs Classifier](https://github.com/Alvi-Rahman/Tensorflow_in_practice_Coursera/blob/master/2.%20Convolutional%20Neural%20Networks%20in%20TensorFlow/Exercise_2_Cats_vs_Dogs_using_augmentation_Question-FINAL.ipynb)

#### Week 3: Transfer Learning

- [Week 3 - Transfer learning (VGG Net)](https://github.com/Alvi-Rahman/Tensorflow_in_practice_Coursera/blob/master/2.%20Convolutional%20Neural%20Networks%20in%20TensorFlow/Exercise_3_Horses_vs_humans_using_Transfer_Learning_Question-FINAL.ipynb)

#### Week 4: Multi-class Classifications

- [Week 4 - Classifying images of sign languages.ipynb](https://github.com/Alvi-Rahman/Tensorflow_in_practice_Coursera/blob/master/2.%20Convolutional%20Neural%20Networks%20in%20TensorFlow/'Exercise_4_Multi_class_classifier_Question-FINAL.ipynb)

## Course 3: Natural Language Processing in TensorFlow

In this third course, you’ll learn how to apply neural networks to solve natural language processing problems using TensorFlow. You’ll learn how to process and represent text through tokenization so that it’s recognizable by a neural network. You’ll be introduced to new types of neural networks, including RNNs, GRUs and LSTMs, and how you can train them to understand the meaning of text. Finally, you’ll learn how to train LSTMs on existing text to create original poetry and more!

#### Week 1: Sentiment in Text

- [Week 1.1 - Detecting sarcasm in news headlines with LSTM and CNN.ipynb](https://github.com/ashishpatel26/Tensorflow-in-practise-Specialization/blob/master/3.%20Natural%20Language%20Processing%20in%20TensorFlow/Week%201.1%20-%20Detecting%20sarcasm%20in%20news%20headlines%20with%20LSTM%20and%20CNN.ipynb)
- [Week 1.2 - Exploring BBC news data.ipynb](https://github.com/ashishpatel26/Tensorflow-in-practise-Specialization/blob/master/3.%20Natural%20Language%20Processing%20in%20TensorFlow/Week%201.2%20-%20Exploring%20BBC%20news%20data.ipynb)

#### Week 2: Word Embeddings

- [Week 2.1 - Classifying IMDB reviews data (Embedding + MLP).ipynb](https://github.com/ashishpatel26/Tensorflow-in-practise-Specialization/blob/master/3.%20Natural%20Language%20Processing%20in%20TensorFlow/Week%202.1%20-%20Classifying%20IMDB%20reviews%20data%20(Embedding%20%2B%20MLP).ipynb)
- [Week 2.2 - Classifying BBC news into topics (Embedding + Conv + MLP).ipynb](https://github.com/ashishpatel26/Tensorflow-in-practise-Specialization/blob/master/3.%20Natural%20Language%20Processing%20in%20TensorFlow/Week%201.2%20-%20Exploring%20BBC%20news%20data.ipynb)

#### Week 3: Sequence Models

- [Week 3.1 - Classifying IMDB reviews (Embedding + Conv1D).ipynb](https://github.com/ashishpatel26/Tensorflow-in-practise-Specialization/blob/master/3.%20Natural%20Language%20Processing%20in%20TensorFlow/Week%203.1%20-%20Classifying%20IMDB%20reviews%20(Embedding%20%2B%20Conv1D).ipynb)
- [Week 3.2 - Twitter sentiment classification (GloVe).ipynb](https://github.com/ashishpatel26/Tensorflow-in-practise-Specialization/blob/master/3.%20Natural%20Language%20Processing%20in%20TensorFlow/Week%203.2%20-%20Twitter%20sentiment%20classification%20(GloVe).ipynb)

#### Week 4: Sequence Models and Literature

- [Week 4 - Poem generation with Bi-directional LSTM.ipynb](https://github.com/ashishpatel26/Tensorflow-in-practise-Specialization/blob/master/3.%20Natural%20Language%20Processing%20in%20TensorFlow/Week%204%20-%20Poem%20generation%20with%20Bi-directional%20LSTM.ipynb)

## Course 4: Sequences, Time Series, and Prediction

In this fourth course, you will learn how to solve time series and forecasting problems in TensorFlow. You’ll first implement best practices to prepare data for time series learning. You’ll also explore how RNNs and ConvNets can be used for predictions. Finally, you’ll apply everything you’ve learned throughout the Specialization to build a sunspot prediction model using real-world data!

#### Week 1: Sequences and Prediction

- [Week 1 - Create and predict synthetic data with time series decomposition.ipynb](https://github.com/ashishpatel26/Tensorflow-in-practise-Specialization/blob/master/4.%20Sequences%20and%20Prediction/Week%201%20-%20Create%20and%20predict%20synthetic%20data%20with%20time%20series%20decomposition.ipynb)

#### Week 2: Deep Neural Networks for Time Series

- [Week 2.1 - Prepare features and labels.ipynb](https://github.com/ashishpatel26/Tensorflow-in-practise-Specialization/blob/master/4.%20Sequences%20and%20Prediction/Week%202.1%20-%20Prepare%20features%20and%20labels.ipynb)
- [Week 2.2 - Predict synthetic data with Linear Regression.ipynb](https://github.com/ashishpatel26/Tensorflow-in-practise-Specialization/blob/master/4.%20Sequences%20and%20Prediction/Week%202.2%20-%20Predict%20synthetic%20data%20with%20Linear%20Regression.ipynb)
- [Week 2.3 - Predict synthetic data with MLP.ipynb](https://github.com/ashishpatel26/Tensorflow-in-practise-Specialization/blob/master/4.%20Sequences%20and%20Prediction/Week%202.3%20-%20Predict%20synthetic%20data%20with%20MLP.ipynb)

#### Week 3: Recurrent Neural Networks for Time Series

- [Week 3.1 - Finding an optimal learning rate for a RNN.ipynb](https://github.com/ashishpatel26/Tensorflow-in-practise-Specialization/blob/master/4.%20Sequences%20and%20Prediction/Week%203.1%20-%20Finding%20an%20optimal%20learning%20rate%20for%20a%20RNN.ipynb)
- [Week 3.2 - LSTM.ipynb](https://github.com/ashishpatel26/Tensorflow-in-practise-Specialization/blob/master/4.%20Sequences%20and%20Prediction/Week%203.2%20-%20LSTM.ipynb)

#### Week 4: Real-world Time Series Data

